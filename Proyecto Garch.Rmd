---
title: "Proyecto GARCH \n Análisis de OMAB, UGPA3 y DIS"
author: "Pablo Garza Moreno \n 000157869"
date: "28 de Abril 2020"
header-includes:
geometry: "landscape"
output:
  html_document:
    classoption: landscape
    fig_height: 9
    fig_width: 20
    number_sections: yes
    toc: yes
    toc_depth: 2
  pdf_document:
    #latex_engine: mactex
    #classoption: landscape
    df_print: kable
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,fig.pos = '!H', comment= NA)
```

```{r loadPackages, echo=F, include=F}
##################xts package########################################
if ("xts" %in% rownames(installed.packages()) == FALSE){
  install.packages("xts",repos = "http://cran.us.r-project.org")
}  
library(xts)

##################urca package########################################
if ("urca" %in% rownames(installed.packages()) == FALSE){
  install.packages("urca",repos = "http://cran.us.r-project.org")
}  
library(urca)

##################rugarch package########################################
if ("rugarch" %in% rownames(installed.packages()) == FALSE){
  install.packages("rugarch",repos = "http://cran.us.r-project.org")
}  
library(rugarch)

##################forecast package########################################
if ("forecast" %in% rownames(installed.packages()) == FALSE){
  install.packages("forecast",repos = "http://cran.us.r-project.org")
} 
library(forecast)

##################forecast package########################################
if ("forecast" %in% rownames(installed.packages()) == FALSE){
  install.packages("forecast",repos = "http://cran.us.r-project.org")
} 
library(forecast)

##################kableExtra package########################################
if ("kableExtra" %in% rownames(installed.packages()) == FALSE){
  install.packages("kableExtra",repos = "http://cran.us.r-project.org")
}
  library(kableExtra)

##################stargazer package########################################
if ("stargazer" %in% rownames(installed.packages()) == FALSE){
  install.packages("stargazer",repos = "http://cran.us.r-project.org")
}
  library(stargazer)

##################knitr package########################################
if ("knitr" %in% rownames(installed.packages()) == FALSE){
  install.packages("knitr",repos = "http://cran.us.r-project.org")
}
  library(knitr)

##################foreign package########################################
if ("foreign" %in% rownames(installed.packages()) == FALSE){
  install.packages("foreign",repos = "http://cran.us.r-project.org")
}
  library(foreign)

##################dplyr package########################################
if ("dplyr" %in% rownames(installed.packages()) == FALSE){
  install.packages("dplyr",repos = "http://cran.us.r-project.org")
}
  library(dplyr)

##################openxlsx package########################################
if ("openxlsx" %in% rownames(installed.packages()) == FALSE){
  install.packages("openxlsx",repos = "http://cran.us.r-project.org")
}
  library(openxlsx)
```


```{r message=FALSE, echo=FALSE}
### read data ###########
data <- read.xlsx("Data/datos000157869.xlsx", detectDates = T)
dataxts <- xts(data[,2:4], order.by = base::as.Date(data[,1],format="%d/%m/%Y" ))

### for plot design ########
my_plot_hook <- function(x, options)
  paste("\n", knitr::hook_plot_tex(x, options), "\n")
knitr::knit_hooks$set(plot = my_plot_hook)

###### log rendimientos ########
rOMA <- diff(log(dataxts[,1]),1) 
rUGPA <- diff(log(dataxts[,2]),1)
rDIS <- diff(log(dataxts[,3]),1)
rOMA <- rOMA[-1]
rUGPA <- rUGPA[-1]
rDIS <- rDIS[-1]

######### training and test sets ########
rOMAtrain <- rOMA["/2019-12-31"]
rUGPAtrain <- rUGPA["/2019-12-31"]
rDIStrain <- rDIS["/2019-12-31"]

rOMAtest <- rOMA["2019-12-31/2020-01-31"]
rUGPAtest <-  rUGPA["2019-12-31/2020-01-31"]
rDIStest <- rUGPA["2019-12-31/2020-01-31"]

rOMAtt <- c(rOMAtrain,rOMAtest)
rUGPAtt <- c(rUGPAtrain,rUGPAtest)
rDIStt <- c(rDIStrain,rDIStest)

```

# INTRODUCCIÓN 
En este proyecto vamos a analizar tres empresas diferentes y analizar la correlación en sus movimientos, precios de Opciones Put con la fórmula de Black-Scholes-Merton, entre otros objetivos. Por lo tanto, ajustaremos 3 modelos GARCH univariados a cada serie de tiempo de logrendimientos. Después, realizaremos un análisis de los modelos multivariados GARCH CCC. Con ayuda de los modelos univariados y los modelos multivariados obtendremos diferentes precios de opciones put para las tres acciones. Finalmente, calcularemos el portafolio de mínima varianza y observaremos la evolución de ese portafolio a través del 2020. 

Antes que nada mencionaremos brevemente el contexto de cada empresa.

Grupo Aeroportuario del Centro Norte (OMA), es una empresa de mantiene y opera las concesiones para más de 10 aeropuertos mexicanos. Los ingresos de la empresa provienen principalmente de la operación del aeropuerto de Monterrey pero tiene otros destinos importantes como Mazatlan, Culiacán, Acapulco, entre otros. 

Ultrapar Participaceos SA (UGPA o Ultrapar), es una empresa brasileña dedicada principalmente a la venta minorista de combustible para automóviles. Tiene 5 segmentos importantes: distrubución de gas (Ultragaz), distribución de combustible (Ipiranga), químicos (Oxiteno), operación de almacenes (Ultracargo) y farmaceúticas (Extrafarma). 

Walt Disney Company (DIS o Disney), es una empresa de entretenimiento que opera globalmente. La empresa opera en cuatro segmentos de negocio: redes de medios, experiencias y productos de parques, estudios de entretenimiento y negocios de venta internacional y directa al consumidor. 

# ANÁLISIS EXPLORATORIO
El primer paso es analizar las series de tiempo de cada uno de los activos. Recordemos que todas las series de tiempo han sido convertidas a USD. 

## Grupo Aeroportuario del Centro Norte
Veamos la serie de tiempo y rendimientos de la empresa.
```{r}

par(mfrow=c(2,2))
plot(dataxts[,1], col ="blue", main = "P") ## OMA
plot(rOMA, col="blue", main="logR")
ind1OMA <- index(rOMA[rOMA==min(rOMA["2016-06-14/2017-06-14"])])
ind1OMANum <- which.min(rOMA["2016-06-14/2017-06-14"])
ind2OMA <- index(rOMA[rOMA==min(rOMA["2018-06-14/2019-01-14"])])
ind5OMA <- index(rOMA[rOMA==max(rOMA["2018-06-14/2019-12-14"])])
```

Se puede ver que existen dos caídas importantes antes de la presencia del COVID-19. Estas caídas se observan en las fechas `r ind1OMA` y `r ind2OMA`. Por otro lado, vemos una subida en la fecha `r ind5OMA` que está fuera de lo común. Además, notamos un cambio en la estructura de la serie a partir del COVID-19. Por lo tanto, graficamos la serie desde Enero de 2020.

```{r}
par(mfrow=c(2,2))
plot(dataxts["2020-01-01/",1], col ="blue", main="P") ## OMA
plot(rOMA["2020-01-01/"], col="blue",main="logR")
ind3OMA <- index(rOMA[rOMA==min(rOMA["2020-01-01/"])])


```
Aquí notamos que la variabilidad de la serie cambia radicalmente a partir del `r ind3OMA`. Desde ese momento la serie tiene muchas caídas pero también recuperaciones en el precio que no van en línea con el comportamiento anteriormente visto.

Ahora graficamos las funciones de autocorrelación y aucorrelación parcial de los rendimientos al cuadrado de OMA, donde solo usaremos los datos de prueba, es decir, hasta el 31 de diciembre de 2019.

```{r}
par(mfrow=c(2,2))
acf(as.numeric(rOMAtrain^2), main="ACF Rendimientos Cuadrados OMA")
pacf(as.numeric(rOMAtrain^2), main="PACF Rendimientos Cuadrados OMA")

```
Notamos una clara relación entre los rendimientos cuadrados y los lags, incluso dando resultados estadísticamente significativos hasta el lag 10 en la gráfica de PACF. Esto podría indicar la presencia de un factor ARCH en la serie.

Finalmente análizamos la simetría de OMA a través de un histograma usando, una vez más, los datos de prueba solamente.

```{r}
par(mfrow=c(2,2))
hist(rOMAtrain,prob=TRUE)
curve(dnorm(x, mean=mean(as.numeric(rOMAtrain)), sd=sqrt(var(as.numeric(rOMAtrain)))),add=TRUE)
qqnorm(rOMAtrain)
qqline(rOMAtrain)
```
Notamos que existen casos extremos y asimétria hacia los casos donde el rendimiento es negativo.

## Ultrapar Participacoes SA
Veamos la serie de tiempo y rendimientos de la empresa.
```{r}
par(mfrow=c(2,2))
plot(dataxts[,2], col ="red", main="P") ## UltraPar
plot(rUGPA, col="red",main="logR")
ind1UGPA <- index(rUGPA[rUGPA==min(rUGPA["2017-12-14/2018-07-14"])])
ind2UGPA <- index(rUGPA[rUGPA==min(rUGPA["2019-01-14/2019-12-14"])])

```

Se puede ver que existen dos caídas importantes antes de la presencia del COVID-19. Estas caídas se observan en las fechas `r ind1UGPA` y `r ind2UGPA`. Además, al igual que OMA notamos un cambio en las estructura de la serie a partir del COVID-19. Por lo tanto, graficamos la serie desde Enero de 2020.
```{r}
par(mfrow=c(2,2))
plot(dataxts["2020-01-01/",2], col ="red", main="P") ## UGPA
plot(rUGPA["2020-01-01/"], col="red",main="logR")
ind3UGPA <- index(rUGPA[rUGPA==min(rUGPA["2020-01-01/"])])
ind4UGPA <- index(rUGPA[rUGPA==max(rUGPA["2020-01-01/"])])
```

Notamos una caída substancial el `r ind3UGPA` y una subida fuera de la norma el `r ind4UGPA`, tan solo un día después. A diferencia de OMA, Ultrapar ha tenido un comportamiento más volátil en términos de subidas y bajadas en el precio de la acción, donde OMA tuvo más caídas al inicio del COVID y Ultrapar a estado cambiando mucho más.

Ahora graficamos las funciones de autocorrelación y aucorrelación parcial de los rendimientos al cuadrado de Ultrapar, donde solo usaremos los datos de prueba, es decir hasta el 31 de diciembre de 2019.

```{r}
par(mfrow=c(2,2))
acf(as.numeric(rUGPAtrain^2), main="ACF Rendimientos Cuadrados Ultrapar")
pacf(as.numeric(rUGPAtrain^2), main="PACF Rendimientos Cuadrados Ultrapar")

```

Notamos que existen lags significativos hasta el lag 15 de la gráfica de PACF lo cuál indica la presencia de factores ARCH en la serie. En la ACF notamos que hasta el lag 6 es significativo lo cuál podría indicar la presencia de un factor GARCH.

Finalmente análizamos la simetría de Ultrapar a través de un histograma usando, una vez más, los datos de prueba solamente.
```{r}
par(mfrow=c(2,2))
hist(rUGPAtrain,prob=TRUE)
curve(dnorm(x, mean=mean(as.numeric(rUGPAtrain)), sd=sqrt(var(as.numeric(rUGPAtrain)))),add=TRUE)
qqnorm(rUGPAtrain)
qqline(rUGPAtrain)
```

Al igual que OMA, tenemos casos extremos pero ahora solamente parecen presentarse en la cola izquierda de la serie. Lo cuál nos habla de asimetría en la serie.

## Walt Disney Co
Veamos la serie de tiempo y rendimientos de la empresa.
```{r}
par(mfrow=c(2,2))
plot(dataxts[,3], col ="black", main="P") ## Disney
plot(rDIS, col="black",main="logR")

ind1DIS <- index(rDIS[rDIS==min(rDIS["2015"])])
ind2DIS <- index(rDIS[rDIS==max(rDIS["2018/2019"])])

```
La serie de tiempo de Disney ha presentado caídas importantes en el tiempo pero a diferencia de OMA y Ultrapar, también ha prsentado subidas fuera de la normalidad. Una caída importante se dio el `r ind1DIS` y la subida importante se da en `r ind2DIS`. Ahora vemos un claro cambio a partir de la presencia del COVID-19. Por lo tanto, graficaremos la serie a partir de enero del 2020. 

```{r}
par(mfrow=c(2,2))
plot(dataxts["2020-01-01/",3], col ="black", main="P") ## DIS
plot(rDIS["2020-01-01/"], col="black",main="logR")
ind3DIS <- index(rDIS[rDIS==min(rDIS["2020-01-01/"])])


```

La serie a partir del COVID también es diferente a la de las anteriores dos empresas analizadas. Notamos que la volatilidad es menor, pero observamos que han teniendo caídas y subidas con muy poco tiempo transcurrido entre ellas. Esta estructura nueva se presenta a partir del `r ind3DIS`.

Ahora graficamos las funciones de autocorrelación y aucorrelación parcial de los rendimientos al cuadrado de Disney, donde solo usaremos los datos de prueba, es decir hasta el 31 de diciembre de 2019.

```{r}
par(mfrow=c(2,2))
acf(as.numeric(rDIStrain^2), main="ACF Rendimientos Cuadrados Disney")
pacf(as.numeric(rDIStrain^2), main="PACF Rendimientos Cuadrados Disney")

```

La serie no presenta mucha correlación con los lags anteriores esto podría verse representado con un modelo con pocos factores anteriores. Sin embargo, sí existen lags significativos en la ACF y en PACF lo cuál podria presentar presencia de ambos factores GARCH y ARCH.

Finalmente análizamos la simetría de Ultrapar a través de un histograma usando, una vez más, los datos de prueba solamente. 
```{r}
par(mfrow=c(2,2))
hist(rDIStrain,prob=TRUE)
curve(dnorm(x, mean=mean(as.numeric(rDIStrain)), sd=sqrt(var(as.numeric(rDIStrain)))),add=TRUE)
qqnorm(rDIStrain)
qqline(rDIStrain)
```
Vemos que la serie presenta colas mas pesadas que la distribución normal pero no parece presentar muchos problemas de asimetría ya que ambas colas son pesadas. Se podría ajustar modelos con colas más pesadas para resolver este problema.

# MODELOS GARCH UNIVARIADOS FINALES

Usaremos los datos hasta finales de 2019 como datos de entrenamiento y los datos de 2020 como datos de prueba. Adicionalmente para cualquier prueba estadística usaremos $\alpha=1\%$ como nivel de confianza.

## Modelos Grupo Aeroportuario del Centro Norte OMA


```{r}

Ntest = nrow(rOMAtest)

### ARCH (1) No Constant ####
rOMA.model1.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,0)),mean.model=list(armaOrder=c(0,0), include.mean=F))
rOMA.model1.fit <- ugarchfit(rOMA.model1.espec,data=rOMAtrain)
rOMA.model1.out <- ugarchfit(spec = rOMA.model1.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model1.forecast <- ugarchforecast(rOMA.model1.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel1 <- fitted(rOMA.model1.forecast)
rOMA.model1.forecast.sigma <- sigma(rOMA.model1.forecast)


MAE <- sum(abs(rOMA.model1.forecast.sigma^2-as.numeric(rOMAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model1.forecast.sigma^2 - as.numeric(rOMAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rOMA.model1.forecast.sigma^2-as.numeric(rOMAtest^2))/abs(as.numeric(rOMAtest^2)))/Ntest

t1 <- cbind(c(MAE,RMSE,MAPE))

```

```{r}
### GARCH (1,1) No Constant ####
rOMA.model2.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F))
rOMA.model2.fit <- ugarchfit(rOMA.model2.espec,data=rOMAtrain)
rOMA.model2.out <- ugarchfit(spec = rOMA.model2.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model2.forecast <- ugarchforecast(rOMA.model2.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel2 <- fitted(rOMA.model2.forecast)
rOMA.model2.forecast.sigma <- sigma(rOMA.model2.forecast)
MAE <- sum(abs(rOMA.model2.forecast.sigma^2-as.numeric(rOMAtest)^2))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model2.forecast.sigma^2 - as.numeric(rOMAtest)^2 )^2 ) / (Ntest) )
MAPE <-sum(  abs(rOMA.model2.forecast.sigma^2 - as.numeric( rOMAtest )^2 ) / abs( as.numeric( rOMAtest )^2)) / Ntest

t2 <- cbind(c(MAE,RMSE,MAPE))


```


```{r}
### GARCH (1,1) No Constant T distribution####
rOMA.model3.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "std")
rOMA.model3.fit <- ugarchfit(rOMA.model3.espec,data=rOMAtrain)
rOMA.model3.out <- ugarchfit(spec = rOMA.model3.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model3.forecast <- ugarchforecast(rOMA.model3.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel3 <- fitted(rOMA.model3.forecast)
rOMA.model3.forecast.sigma <- sigma(rOMA.model3.forecast)
MAE <- sum(abs(rOMA.model3.forecast.sigma^2-as.numeric(rOMAtest)^2))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model3.forecast.sigma^2 - as.numeric(rOMAtest)^2 )^2 ) / (Ntest) )
MAPE <-sum(  abs(rOMA.model3.forecast.sigma^2 - as.numeric( rOMAtest )^2 ) / abs( as.numeric( rOMAtest )^2)) / Ntest

t3 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (1,1) No Constant GED distribution####
rOMA.model4.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "ged")
rOMA.model4.fit <- ugarchfit(rOMA.model4.espec,data=rOMAtrain)
rOMA.model4.out <- ugarchfit(spec = rOMA.model4.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model4.forecast <- ugarchforecast(rOMA.model4.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel4 <- fitted(rOMA.model4.forecast)
rOMA.model4.forecast.sigma <- sigma(rOMA.model4.forecast)
MAE <- sum(abs(rOMA.model4.forecast.sigma^2-as.numeric(rOMAtest)^2))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model4.forecast.sigma^2 - as.numeric(rOMAtest)^2 )^2 ) / (Ntest) )
MAPE <-sum(  abs(rOMA.model4.forecast.sigma^2 - as.numeric( rOMAtest )^2 ) / abs( as.numeric( rOMAtest )^2)) / Ntest

t4 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GJR-GARCH (1,1) No Constant t distribution####

rOMA.model5.espec <- ugarchspec(variance.model=list(model="gjrGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "std")
rOMA.model5.fit <- ugarchfit(rOMA.model5.espec,data=rOMAtrain)
rOMA.model5.out <- ugarchfit(spec = rOMA.model5.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model5.forecast <- ugarchforecast(rOMA.model5.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel5 <- fitted(rOMA.model5.forecast)
rOMA.model5.forecast.sigma <- sigma(rOMA.model5.forecast)
MAE <- sum(abs(rOMA.model5.forecast.sigma^2-as.numeric(rOMAtest)^2))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model5.forecast.sigma^2 - as.numeric(rOMAtest)^2 )^2 ) / (Ntest) )
MAPE <-sum(  abs(rOMA.model5.forecast.sigma^2 - as.numeric( rOMAtest )^2 ) / abs( as.numeric( rOMAtest )^2)) / Ntest

t5 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### E-GARCH (1,1) No Constant T distribution####

rOMA.model6.espec <- ugarchspec(variance.model=list(model="eGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "std")
rOMA.model6.fit <- ugarchfit(rOMA.model6.espec,data=rOMAtrain)
rOMA.model6.out <- ugarchfit(spec = rOMA.model6.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model6.forecast <- ugarchforecast(rOMA.model6.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel6 <- fitted(rOMA.model6.forecast)
rOMA.model6.forecast.sigma <- sigma(rOMA.model6.forecast)
MAE <- sum(abs(rOMA.model6.forecast.sigma^2-as.numeric(rOMAtest)^2))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model6.forecast.sigma^2 - as.numeric(rOMAtest)^2 )^2 ) / (Ntest) )
MAPE <-sum(  abs(rOMA.model6.forecast.sigma^2 - as.numeric( rOMAtest )^2 ) / abs( as.numeric( rOMAtest )^2)) / Ntest

t6 <- cbind(c(MAE,RMSE,MAPE))
```

El modelo seleccionado, EGARCH (1,1) NC GED con Indicadoras para los casos atípicos, arroja los siguientes valores:
```{r}
### E-GARCH (1,1) No Constant GED distribution Indicator####
## Creación Indicadoras ######

ind1OMAVec <- rep(0,length(rOMAtrain))

ind1OMAVec[which(index(rOMA)==ind1OMA)] <- 1

ind2OMAVec <- rep(0,length(rOMAtrain))
ind2OMAVec[which(index(rOMA)==ind2OMA)] <- 1

ind5OMAVec <- rep(0,length(rOMAtrain))
ind5OMAVec[which(index(rOMA)==ind5OMA)] <- 1

indicators <- as.matrix(cbind(ind1OMAVec,ind2OMAVec,ind5OMAVec))

rOMA.model7.espec <- ugarchspec(
  variance.model=list(model="eGARCH",garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F,external.regressors = indicators),
  distribution.model = "ged")

rOMA.model7.fit <- ugarchfit(rOMA.model7.espec,data=rOMAtrain)
rOMA.model7.fit

rOMA.model7.out <- ugarchfit(spec = rOMA.model7.espec, data=rOMAtt, out.sample = Ntest)
rOMA.model7.forecast <- ugarchforecast(rOMA.model7.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel7 <- fitted(rOMA.model7.forecast)
rOMA.model7.forecast.sigma <- sigma(rOMA.model7.forecast)
MAE <- sum(abs(rOMA.model7.forecast.sigma^2-as.numeric(rOMAtest)^2))/(Ntest)
RMSE <- sqrt( sum( ( rOMA.model7.forecast.sigma^2 - as.numeric(rOMAtest)^2 )^2 ) / (Ntest) )
MAPE <-sum(  abs(rOMA.model7.forecast.sigma^2 - as.numeric( rOMAtest )^2 ) / abs( as.numeric( rOMAtest )^2)) / Ntest

t7 <- cbind(c(MAE,RMSE,MAPE))

```
Donde es importante ver que ambos signos de asimétria son no significativos y al 1% el sign bias tampoco es significativo. Adicionalmente, todos los parámetros son significativos al 1%. Veamos que las pruebas de Ljung-Box confirman que no hay autocorrelación.

```{r}
########### Crear tabla con AIC y BIC ###########
AIC=c(infocriteria(rOMA.model1.fit)[1],
infocriteria(rOMA.model2.fit)[1],
infocriteria(rOMA.model3.fit)[1],
infocriteria(rOMA.model4.fit)[1],
infocriteria(rOMA.model5.fit)[1],
infocriteria(rOMA.model6.fit)[1],
infocriteria(rOMA.model7.fit)[1])

BIC=c(infocriteria(rOMA.model1.fit)[2],
infocriteria(rOMA.model2.fit)[2],
infocriteria(rOMA.model3.fit)[2],
infocriteria(rOMA.model4.fit)[2],
infocriteria(rOMA.model5.fit)[2],
infocriteria(rOMA.model6.fit)[2],
infocriteria(rOMA.model7.fit)[2])

N=nrow(rOMAtrain)
t <- rbind(AIC*N,BIC*N)
modMin <- apply(t,1,which.min)
t <- cbind(t,modMin)
colnames(t) <- c("1. ARCH (1) NC",
                "2. GARCH (1,1) NC" ,
                "3. GARCH (1,1) NC t-Student",
                "4. GARCH (1,1) NC GED",
                "5. GJR-GARCH (1,1) NC t-Student",
                "6. EGARCH (1,1) NC t-Student",
                "7. EGARCH (1,1) NC GED Indicators",
                "Modelo Mínimo")

rownames(t) <- c("AIC","BIC")
kable(t(t), digits=4)%>%
  kable_styling(position = "center")


tab2 <- cbind(t1,t2,t3,t4,t5,t6,t7)
modMin <- apply(tab2,1,which.min)
tab2 <- cbind(tab2,modMin)

rownames(tab2) <- c("MAE","RMSE","MAPE")
colnames(tab2) <- c(colnames(t))
kable(t(tab2),digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Medidas predictivas sobre la varianza condicional pronosticada")

```

El modelo 7, EGARCH (1,1) NC GED Indicators, fue seleccionado por tener el menor AIC y BIC, adicionalmente las indicadoras son para los returnos mencionados en el análisis exploratorio, como si fueran caso atípicos. Además, el modelo escogido, también tiene el menor error en las medidas predictivas.

Ahora vemos el pronóstico step by step y la validación del modelo.

```{r}
#### Validación modelos OMA
# 
# #### Model 5 #####
# rOMA.model5.fit.res <- residuals(rOMA.model5.fit)/sigma(rOMA.model5.fit)
# plot(rOMA.model5.fit.res)
# 
# plot(rOMA.model5.fit, which = "all")
# Box.test(rOMA.model5.fit.res^2,lag=2,type="Ljung-Box")
# 
# #### Model 6 #####
# rOMA.model6.fit.res <- residuals(rOMA.model6.fit)/sigma(rOMA.model6.fit)
# plot(rOMA.model6.fit.res)
# 
# plot(rOMA.model6.fit, which = "all")
# Box.test(rOMA.model6.fit.res^2,lag=2,type="Ljung-Box")

#### Model 7 #####
rOMA.model7.fit.res <- residuals(rOMA.model7.fit)/sigma(rOMA.model7.fit)

par(mfrow=c(2,2))
plot(rOMA.model7.forecast, which = 2)
plot(rOMA.model7.forecast, which = 4)

par(mfrow=c(2,2))
plot(rOMA.model7.fit.res)

par(mfrow=c(2,2))
plot(rOMA.model7.fit, which = 3)
plot(rOMA.model7.fit, which = 9)
plot(rOMA.model7.fit, which = 11)
plot(rOMA.model7.fit, which = 12)
Box.test(rOMA.model7.fit.res^2,lag=2,type="Ljung-Box")
Box.test(rOMA.model7.fit.res^2,lag=5,type="Ljung-Box")
Box.test(rOMA.model7.fit.res^2,lag=10,type="Ljung-Box")
Box.test(rOMA.model7.fit.res^2,lag=20,type="Ljung-Box")
Box.test(rOMA.model7.fit.res^2,lag=30,type="Ljung-Box")


```
Veamos que solamente un lag significativo en la ACF, pero con las pruebas de Ljung-Box para 2,5,10,20,30 lags confirmamos que la autocorrelación es cero ya que es mayor a 1%. Por lo tanto, el modelo queda validado.

## Modelos Ultrapar Participacoes SA
Ahora queremos ajustar un modelo para UGPA.

```{r}

Ntest = nrow(rUGPAtest)

### ARCH (1) Constant ####
rUGPA.model1.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,0)),mean.model=list(armaOrder=c(0,0), include.mean=T))
rUGPA.model1.fit <- ugarchfit(rUGPA.model1.espec,data=rUGPAtrain)
rUGPA.model1.out <- ugarchfit(spec = rUGPA.model1.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model1.forecast <- ugarchforecast(rUGPA.model1.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel1 <- fitted(rUGPA.model1.forecast)
rUGPA.model1.forecast.sigma <- sigma(rUGPA.model1.forecast)

MAE <- sum(abs(rUGPA.model1.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model1.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model1.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t1 <- cbind(c(MAE,RMSE,MAPE))

```

```{r}
### GARCH (1,1) No Constant ####
rUGPA.model2.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F))
rUGPA.model2.fit <- ugarchfit(rUGPA.model2.espec,data=rUGPAtrain)
rUGPA.model2.out <- ugarchfit(spec = rUGPA.model2.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model2.forecast <- ugarchforecast(rUGPA.model2.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel2 <- fitted(rUGPA.model2.forecast)
rUGPA.model2.forecast.sigma <- sigma(rUGPA.model2.forecast)

MAE <- sum(abs(rUGPA.model2.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model2.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model2.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t2 <- cbind(c(MAE,RMSE,MAPE))

```


```{r}
### GARCH (1,1) No Constant T distribution####
rUGPA.model3.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "std")
rUGPA.model3.fit <- ugarchfit(rUGPA.model3.espec,data=rUGPAtrain)
rUGPA.model3.out <- ugarchfit(spec = rUGPA.model3.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model3.forecast <- ugarchforecast(rUGPA.model3.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel3 <- fitted(rUGPA.model3.forecast)
rUGPA.model3.forecast.sigma <- sigma(rUGPA.model3.forecast)

MAE <- sum(abs(rUGPA.model3.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model3.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model3.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t3 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (1,2) No Constant T distribution####
rUGPA.model4.espec <- ugarchspec(
  variance.model=list(model="sGARCH",garchOrder=c(1,2)),
  mean.model=list(armaOrder=c(0,0), include.mean=F), 
  distribution.model = "std")

rUGPA.model4.fit <- ugarchfit(rUGPA.model4.espec,data=rUGPAtrain)
rUGPA.model4.out <- ugarchfit(spec = rUGPA.model4.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model4.forecast <- ugarchforecast(rUGPA.model4.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel4 <- fitted(rUGPA.model4.forecast)
rUGPA.model4.forecast.sigma <- sigma(rUGPA.model4.forecast)

MAE <- sum(abs(rUGPA.model4.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model4.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model4.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t4 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (1,1) No Constant GED distribution####

rUGPA.model5.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "ged")
rUGPA.model5.fit <- ugarchfit(rUGPA.model5.espec,data=rUGPAtrain)
rUGPA.model5.out <- ugarchfit(spec = rUGPA.model5.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model5.forecast <- ugarchforecast(rUGPA.model5.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel5 <- fitted(rUGPA.model5.forecast)
rUGPA.model5.forecast.sigma <- sigma(rUGPA.model5.forecast)

MAE <- sum(abs(rUGPA.model5.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model5.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model5.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t5 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (2,1) No Constant GED distribution####

rUGPA.model6.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(2,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "ged")
rUGPA.model6.fit <- ugarchfit(rUGPA.model6.espec,data=rUGPAtrain)
rUGPA.model6.out <- ugarchfit(spec = rUGPA.model6.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model6.forecast <- ugarchforecast(rUGPA.model6.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel6 <- fitted(rUGPA.model6.forecast)
rUGPA.model6.forecast.sigma <- sigma(rUGPA.model6.forecast)

MAE <- sum(abs(rUGPA.model6.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model6.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model6.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t6 <- cbind(c(MAE,RMSE,MAPE))
```

Los resultados del modelo escogido,GARCH (1,1) NC GED con Indicadoras para casos atípicos, son:
```{r}
### GARCH (1,1) No Constant GED distribution Indicator####
## Creación Indicadoras ######


ind1UGPAVec <- rep(0,length(rUGPAtrain))
ind1UGPAVec[which(index(rUGPA)==ind1UGPA)] <- 1

ind2UGPAVec <- rep(0,length(rUGPAtrain))
ind2UGPAVec[which(index(rUGPA)==ind2UGPA)] <- 1

indicators <- as.matrix(cbind(ind1UGPAVec,ind2UGPAVec))

rUGPA.model7.espec <- ugarchspec(
  variance.model=list(model="sGARCH",garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F,external.regressors = indicators),
  distribution.model = "ged")

rUGPA.model7.fit <- ugarchfit(rUGPA.model7.espec,data=rUGPAtrain)
rUGPA.model7.fit

rUGPA.model7.out <- ugarchfit(spec = rUGPA.model7.espec, data=rUGPAtt, out.sample = Ntest)
rUGPA.model7.forecast <- ugarchforecast(rUGPA.model7.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel7 <- fitted(rUGPA.model7.forecast)
rUGPA.model7.forecast.sigma <- sigma(rUGPA.model7.forecast)

MAE <- sum(abs(rUGPA.model7.forecast.sigma^2-as.numeric(rUGPAtest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rUGPA.model7.forecast.sigma^2 - as.numeric(rUGPAtest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rUGPA.model7.forecast.sigma^2-as.numeric(rUGPAtest^2))/abs(as.numeric(rUGPAtest^2)))/Ntest

t7 <- cbind(c(MAE,RMSE,MAPE))

```
Donde notamos que todos los parámetros menos omega son significativos al 1% y todos son a un 10%. Adicionalmente, las pruebas de Ljung-Box determinan que no existe autocorrelación conjunta. Veamos también que la prueba de signo tiene valor no significativos, por lo que no hay problemas de asímetria. De esta manera, el modelo no corrige estos problemas, solamente corregimos el problema de las colas pesadas con una distribución GED.


```{r}
########### Crear tabla con AIC y BIC ###########
AIC=c(infocriteria(rUGPA.model1.fit)[1],
infocriteria(rUGPA.model2.fit)[1],
infocriteria(rUGPA.model3.fit)[1],
infocriteria(rUGPA.model4.fit)[1],
infocriteria(rUGPA.model5.fit)[1],
infocriteria(rUGPA.model6.fit)[1],
infocriteria(rUGPA.model7.fit)[1])

BIC=c(infocriteria(rUGPA.model1.fit)[2],
infocriteria(rUGPA.model2.fit)[2],
infocriteria(rUGPA.model3.fit)[2],
infocriteria(rUGPA.model4.fit)[2],
infocriteria(rUGPA.model5.fit)[2],
infocriteria(rUGPA.model6.fit)[2],
infocriteria(rUGPA.model7.fit)[2])

N=nrow(rUGPAtrain)
t <- rbind(AIC*N,BIC*N)
modMin <- apply(t,1,which.min)
t <- cbind(t,modMin)
colnames(t) <- c("1. ARCH (1) ",
                "2. GARCH (1,1) NC" ,
                "3. GARCH (1,1) NC t-Student",
                "4. GARCH (1,2) NC t-Student",
                "5. GARCH (1,1) NC GED",
                "6. GARCH (2,1) NC GED",
                "7. GARCH (1,1) NC GED Indicators"
                ,"Modelo Mínimo")

rownames(t) <- c("AIC","BIC")
kable(t(t), digits=4)%>%
  kable_styling(position = "center")

tab2 <- cbind(t1,t2,t3,t4,t5,t6,t7)
modMin <- apply(tab2,1,which.min)
tab2 <- cbind(tab2,modMin)

rownames(tab2) <- c("MAE","RMSE","MAPE")
colnames(tab2) <- c(colnames(t))
kable(t(tab2),digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Medidas predictivas sobre la varianza condicional pronosticada")

```
Notemos que el modelo 7, GARCH (1,1) NC GED Indicators es el que menor AIC y BIC tiene de todos los escogidos. Donde las indicadores solamente afectan a la media y son para corregir por los dos valores atípicos descritos en el análisis exploratorio. Notamos que solamente en RMSE el modelo seleccionado no es el mejor, pero la diferencia es muy poca. Por lo tanto, parece ser un buen modelo en ambos sentidos.

Ahora falta validarlo y ver las predicciones en logrendimientos.

```{r}
#### Validación modelos UGPA

#### Model 3 #####
# rUGPA.model3.fit.res <- residuals(rUGPA.model3.fit)/sigma(rUGPA.model3.fit)
# plot(rUGPA.model3.fit.res)
# 
# plot(rUGPA.model3.fit, which = "all")
# Box.test(rUGPA.model3.fit.res^2,lag=2,type="Ljung-Box")

# #### Model 5 #####
# rUGPA.model5.fit.res <- residuals(rUGPA.model5.fit)/sigma(rUGPA.model5.fit)
# plot(rUGPA.model5.fit.res)
# 
# plot(rUGPA.model5.fit, which = "all")
# Box.test(rUGPA.model5.fit.res^2,lag=2,type="Ljung-Box")

#### Model 7 #####
rUGPA.model7.fit.res <- residuals(rUGPA.model7.fit)/sigma(rUGPA.model7.fit)
par(mfrow=c(2,2))
plot(rUGPA.model1.forecast,which=2)
plot(rUGPA.model1.forecast,which=4)

par(mfrow=c(2,2))
plot(rUGPA.model7.fit.res)



par(mfrow=c(2,2))
plot(rUGPA.model7.fit, which = 3)
plot(rUGPA.model7.fit, which = 9)
plot(rUGPA.model7.fit, which = 11)
plot(rUGPA.model7.fit, which = 12)
Box.test(rUGPA.model7.fit.res^2,lag=2,type="Ljung-Box")
Box.test(rUGPA.model7.fit.res^2,lag=5,type="Ljung-Box")
Box.test(rUGPA.model7.fit.res^2,lag=10,type="Ljung-Box")
Box.test(rUGPA.model7.fit.res^2,lag=20,type="Ljung-Box")
Box.test(rUGPA.model7.fit.res^2,lag=30,type="Ljung-Box")


```
El ajuste a una distribución GED es bastante preciso, adicionalmente ninguna autocorrelación es significativa para los errores estandarizados al cuadrado. Finalmente con las pruebas de Ljung-Box para 2,5,10,20,30 lags notamos que todas tiene valor p mayor a 1%, lo cuál confirma que no exista autocorrelación conjunta. Por lo tanto, el modelo queda validado. 


## Modelos Walt Disney Co
Ahora queremos ajustar un modelo para Disney.

```{r}

Ntest = nrow(rDIStest)

### ARCH (1) Constant ####
rDIS.model1.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,0)),mean.model=list(armaOrder=c(0,0), include.mean=T))
rDIS.model1.fit <- ugarchfit(rDIS.model1.espec,data=rDIStrain)
rDIS.model1.out <- ugarchfit(spec = rDIS.model1.espec, data=rDIStt, out.sample = Ntest)
rDIS.model1.forecast <- ugarchforecast(rDIS.model1.out, n.ahead=1,n.roll=Ntest-1)
rDIS.model1.forecast.sigma <- sigma(rDIS.model1.forecast)

MAE <- sum(abs(rDIS.model1.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model1.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model1.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t1 <- cbind(c(MAE,RMSE,MAPE))


```

```{r}
### GARCH (1,1) Constant ####
rDIS.model2.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=T))
rDIS.model2.fit <- ugarchfit(rDIS.model2.espec,data=rDIStrain)
rDIS.model2.out <- ugarchfit(spec = rDIS.model2.espec, data=rDIStt, out.sample = Ntest)
rDIS.model2.forecast <- ugarchforecast(rDIS.model2.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel2 <- fitted(rDIS.model2.forecast)
rDIS.model2.forecast.sigma <- sigma(rDIS.model2.forecast)

MAE <- sum(abs(rDIS.model2.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model2.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model2.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t2 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (1,1) No Constant T distribution####
rDIS.model3.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "std")
rDIS.model3.fit <- ugarchfit(rDIS.model3.espec,data=rDIStrain)
rDIS.model3.out <- ugarchfit(spec = rDIS.model3.espec, data=rDIStt, out.sample = Ntest)
rDIS.model3.forecast <- ugarchforecast(rDIS.model3.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel3 <- fitted(rDIS.model3.forecast)
rDIS.model3.forecast.sigma <- sigma(rDIS.model3.forecast)

MAE <- sum(abs(rDIS.model3.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model3.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model3.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t3 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (0,1) No Constant T distribution####
rDIS.model4.espec <- ugarchspec(
  variance.model=list(model="sGARCH",garchOrder=c(0,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F), 
  distribution.model = "std")

rDIS.model4.fit <- ugarchfit(rDIS.model4.espec,data=rDIStrain)
rDIS.model4.out <- ugarchfit(spec = rDIS.model4.espec, data=rDIStt, out.sample = Ntest)
rDIS.model4.forecast <- ugarchforecast(rDIS.model4.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel4 <- fitted(rDIS.model4.forecast)
rDIS.model4.forecast.sigma <- sigma(rDIS.model4.forecast)

MAE <- sum(abs(rDIS.model4.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model4.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model4.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t4 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (1,1) No Constant GED distribution####

rDIS.model5.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,1)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "ged")
rDIS.model5.fit <- ugarchfit(rDIS.model5.espec,data=rDIStrain)
rDIS.model5.out <- ugarchfit(spec = rDIS.model5.espec, data=rDIStt, out.sample = Ntest)
rDIS.model5.forecast <- ugarchforecast(rDIS.model5.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel5 <- fitted(rDIS.model5.forecast)
rDIS.model5.forecast.sigma <- sigma(rDIS.model5.forecast)

MAE <- sum(abs(rDIS.model5.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model5.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model5.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t5 <- cbind(c(MAE,RMSE,MAPE))
```


```{r}
### GARCH (1,2) No Constant GED distribution####

rDIS.model6.espec <- ugarchspec(variance.model=list(model="sGARCH",garchOrder=c(1,2)),mean.model=list(armaOrder=c(0,0), include.mean=F), distribution.model = "ged")
rDIS.model6.fit <- ugarchfit(rDIS.model6.espec,data=rDIStrain)
rDIS.model6.out <- ugarchfit(spec = rDIS.model6.espec, data=rDIStt, out.sample = Ntest)
rDIS.model6.forecast <- ugarchforecast(rDIS.model6.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel6 <- fitted(rDIS.model6.forecast)
rDIS.model6.forecast.sigma <- sigma(rDIS.model6.forecast)

MAE <- sum(abs(rDIS.model6.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model6.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model6.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t6 <- cbind(c(MAE,RMSE,MAPE))
```

Los resultados del modelo escogido, GARCH (1,1) NC t-Student con Indicadoras, son:
```{r}
### GARCH (1,1) No Constant t distribution Indicator####
## Creación Indicadoras ######

ind1DISVec <- rep(0,length(rDIStrain))
ind1DISVec[which(index(rDIS)==ind1DIS)] <- 1

ind2DISVec <- rep(0,length(rDIStrain))
ind2DISVec[which(index(rDIS)==ind2DIS)] <- 1

indicators <- as.matrix(cbind(ind1DISVec,ind2DISVec))

rDIS.model7.espec <- ugarchspec(
  variance.model=list(model="sGARCH",garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F,external.regressors = indicators),
  distribution.model = "std")

rDIS.model7.fit <- ugarchfit(rDIS.model7.espec,data=rDIStrain)
rDIS.model7.fit

rDIS.model7.out <- ugarchfit(spec = rDIS.model7.espec, data=rDIStt, out.sample = Ntest)
rDIS.model7.forecast <- ugarchforecast(rDIS.model7.out, n.ahead=1,n.roll=Ntest-1)
fittedmodel7 <- fitted(rDIS.model7.forecast)
rDIS.model7.forecast.sigma <- sigma(rDIS.model7.forecast)

MAE <- sum(abs(rDIS.model7.forecast.sigma^2-as.numeric(rDIStest^2)))/(Ntest)
RMSE <- sqrt( sum( ( rDIS.model7.forecast.sigma^2 - as.numeric(rDIStest^2) )^2 ) / (Ntest) )
MAPE <- sum(abs(rDIS.model7.forecast.sigma^2-as.numeric(rDIStest^2))/abs(as.numeric(rDIStest^2)))/Ntest

t7 <- cbind(c(MAE,RMSE,MAPE))

```

Notemos que no hay problemas con la asimetría. Adicionalmente vemos que solamente omega y alpha_1 no son significativos al 1% pero que alpha1 si es a 10%, pero no queremos eliminarlas del modelo para no cambiar su estructura. Adicionalmente, las pruebas de Ljung-Box demuestran que no hay correlación conjunta.

```{r}
########### Crear tabla con AIC y BIC ###########
AIC=c(infocriteria(rDIS.model1.fit)[1],
infocriteria(rDIS.model2.fit)[1],
infocriteria(rDIS.model3.fit)[1],
infocriteria(rDIS.model4.fit)[1],
infocriteria(rDIS.model5.fit)[1],
infocriteria(rDIS.model6.fit)[1],
infocriteria(rDIS.model7.fit)[1])

BIC=c(infocriteria(rDIS.model1.fit)[2],
infocriteria(rDIS.model2.fit)[2],
infocriteria(rDIS.model3.fit)[2],
infocriteria(rDIS.model4.fit)[2],
infocriteria(rDIS.model5.fit)[2],
infocriteria(rDIS.model6.fit)[2],
infocriteria(rDIS.model7.fit)[2])

N=nrow(rDIStrain)
t <- rbind(AIC*N,BIC*N)
modMin <- apply(t,1,which.min)
t <- cbind(t,modMin)
colnames(t) <- c("1. ARCH (1) ",
                "2. GARCH (1,1) " ,
                "3. GARCH (1,1) NC t-Student",
                "4. GARCH (0,1) NC t-Student",
                "5. GARCH (1,1) NC GED",
                "6. GARCH (1,2) NC GED",
                "7. GARCH (1,1) NC t-Student Indicators"
                ,"Modelo Mínimo")

rownames(t) <- c("AIC","BIC")
kable(t(t), digits=4)%>%
  kable_styling(position = "center")


tab2 <- cbind(t1,t2,t3,t4,t5,t6,t7)
modMin <- apply(tab2,1,which.min)
tab2 <- cbind(tab2,modMin)

rownames(tab2) <- c("MAE","RMSE","MAPE")
colnames(tab2) <- c(colnames(t))
kable(t(tab2),digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Medidas predictivas sobre la varianza condicional pronosticada")

```
Notemos que el modelo 7, GARCH (1,1) NC GED Indicators es el que menor AIC y BIC tiene de todos los escogidos. Donde las indicadores solamente afectan a la media y son para corregir por los dos valores atípicos descritos en el análisis exploratorio. Es importante recalcar que el modelo escogido no fue el mejor en MAPE y MAE, pero sí en RMSE.

Ahora falta validarlo y ver las predicciones en logrendimientos.

```{r}
#### Validación modelos Disney

#### Model 3 #####
# rDIS.model3.fit.res <- residuals(rDIS.model3.fit)/sigma(rDIS.model3.fit)
# plot(rDIS.model3.fit.res)
# 
# plot(rDIS.model3.fit, which = "all")
# Box.test(rDIS.model3.fit.res^2,lag=2,type="Ljung-Box")

# #### Model 5 #####
# rDIS.model5.fit.res <- residuals(rDIS.model5.fit)/sigma(rDIS.model5.fit)
# plot(rDIS.model5.fit.res)
# 
# plot(rDIS.model5.fit, which = "all")
# Box.test(rDIS.model5.fit.res^2,lag=2,type="Ljung-Box")

#### Model 7 #####
rDIS.model7.fit.res <- residuals(rDIS.model7.fit)/sigma(rDIS.model7.fit)
par(mfrow=c(2,2))
plot(rDIS.model7.forecast, which=2)
plot(rDIS.model7.forecast, which=4)

par(mfrow=c(2,2))
plot(rDIS.model7.fit.res)

par(mfrow=c(2,2))
plot(rDIS.model7.fit, which = 3)
plot(rDIS.model7.fit, which = 9)
plot(rDIS.model7.fit, which = 11)
plot(rDIS.model7.fit, which = 12)
Box.test(rDIS.model7.fit.res^2,lag=2,type="Ljung-Box")
Box.test(rDIS.model7.fit.res^2,lag=5,type="Ljung-Box")
Box.test(rDIS.model7.fit.res^2,lag=10,type="Ljung-Box")
Box.test(rDIS.model7.fit.res^2,lag=20,type="Ljung-Box")
Box.test(rDIS.model7.fit.res^2,lag=30,type="Ljung-Box")


```
El ajuste a una distribución t-Studen es bastante preciso, adicionalmente solamente una autocorrelación es significativa pero antes de 23 lags todas son no significativas. Finalmente con las pruebas de Ljung-Box para 2,5,10,20,30 lags notamos que todas tiene valor p mayor a 1%, lo cuál confirma que no existe autocorrelación conjunta. Por lo tanto, el modelo queda validado.

# MODELO MULTIVARIADO GARCH CCC

## Matriz de correlaciones de rendimientos al 31/12/2019

Ahora queremos construir la matriz de correlaciones del modelo GARCH CCC.
Aquí vemos la matriz de correlación de los rendimientos de los modelos.
```{r}

C <- cor(x=cbind(rOMA.model7.fit.res,rUGPA.model7.fit.res,rDIS.model7.fit.res),
         y=cbind(rOMA.model7.fit.res,rUGPA.model7.fit.res,rDIS.model7.fit.res))
rownames(C) <- c("OMA Res Est","UGPA Res Est","DIS Res Est")
colnames(C) <- c("OMA Res Est","UGPA Res Est","DIS Res Est")
kable(C,digits=4)%>%
  kable_styling(position = "center")
```

## Matriz de covarianza de precios al 31/12/2019

```{r}


taux <- which(index(rOMA)==index(tail(rOMAtrain,1)))
sigmaOMAt <- sigma(rOMA.model1.fit)[taux]
sigmaUGPAt <- sigma(rUGPA.model1.fit)[taux]
sigmaDISt  <- sigma(rDIS.model1.fit)[taux]

Dt <- diag(x=as.numeric(c(sigmaOMAt,sigmaUGPAt,sigmaDISt)))
Ht <- Dt%*%C%*%Dt
pOMAt <- as.numeric(dataxts[taux+1,1])
pUPGAt <- as.numeric(dataxts[taux+1,2])
pDISt <- as.numeric(dataxts[taux+1,3])
pt <- c(pOMAt,pUPGAt,pDISt)


covPrecio <- matrix(0,3,3)
covPrecio[1,1] <- pt[1]^2*exp(Ht[1,1])*(exp(Ht[1,1])-1)
covPrecio[2,2] <- pt[2]^2*exp(Ht[2,2])*(exp(Ht[2,2])-1)
covPrecio[3,3] <- pt[3]^2*exp(Ht[3,3])*(exp(Ht[3,3])-1)
covPrecio[1,2] <- pt[1]*pt[2]*exp((Ht[1,1]+Ht[2,2])*.5)*(exp(Ht[1,2])-1)
covPrecio[1,3] <- pt[1]*pt[3]*exp((Ht[1,1]+Ht[3,3])*.5)*(exp(Ht[1,3])-1)
covPrecio[2,3] <- pt[2]*pt[3]*exp((Ht[2,2]+Ht[3,3])*.5)*(exp(Ht[2,3])-1)
covPrecio[3,2] <- covPrecio[2,3]
covPrecio[3,1]<- covPrecio[1,3]
covPrecio[2,1] <- covPrecio[1,2]

rownames(covPrecio) <- c("OMA","UGPA","DIS")
colnames(covPrecio) <- c("OMA","UGPA","DIS")
kable(covPrecio,digits=5)%>%
  kable_styling(position = "center")


```

## Matriz de covarianza de precios al 31/01/2020

Ahora queremos repetir el procedimiento para los pronósticos dinámicos y para los pronósticos step-by-step de los precios de cada activo hasta el 31 de enero de 2020. Empezamos con los step-by-step.

```{r}
######### Step by Step .###########
n <- nrow(rOMA["2020-01"])
rOMA.model7.out <- ugarchfit(spec = rOMA.model7.espec, data=rOMA["/2020-01-31"], out.sample = n )
rOMA.model7.forecast <- ugarchforecast(rOMA.model7.out, n.ahead=1,n.roll=n-1)
rOMA.model7.forecast.sigma <- sigma(rOMA.model7.forecast)


rUGPA.model7.out <- ugarchfit(spec = rUGPA.model7.espec, data=rUGPA["/2020-01-31"], out.sample = n )
rUGPA.model7.forecast <- ugarchforecast(rUGPA.model7.out, n.ahead=1,n.roll=n-1)
rUGPA.model7.forecast.sigma <- sigma(rUGPA.model7.forecast)


rDIS.model7.out <- ugarchfit(spec = rDIS.model7.espec, data=rDIS["/2020-01-31"], out.sample = n )
rDIS.model7.forecast <- ugarchforecast(rDIS.model7.out, n.ahead=1,n.roll=n-1)
rDIS.model7.forecast.sigma <- sigma(rDIS.model7.forecast)


sigmaOMAt <- rOMA.model7.forecast.sigma[n]
sigmaUGPAt <- rUGPA.model7.forecast.sigma[n]
sigmaDISt  <- rDIS.model7.forecast.sigma[n]


# preciosOMAss1 <- as.numeric(dataxts["2019-12-30/2020-01-30",1])*exp(rOMA.model7.forecast.sigma*.5)
# preciosUGPAss1 <- as.numeric(dataxts["2019-12-30/2020-01-30",2])*exp(rUGPA.model7.forecast.sigma*.5)
# preciosDISss1 <- as.numeric(dataxts["2019-12-30/2020-01-30",3])*exp(rDIS.model7.forecast.sigma*.5)

Dt <- diag(x=as.numeric(c(sigmaOMAt,sigmaUGPAt,sigmaDISt)))
Ht <- Dt%*%C%*%Dt
pOMAt <- dataxts[taux+n,1]
pUPGAt <- dataxts[taux+n,2]
pDISt <- dataxts[taux+n,3]
pt <- c(pOMAt,pUPGAt,pDISt)


covPrecio <- matrix(0,3,3)
covPrecio[1,1] <- pt[1]^2*exp(Ht[1,1])*(exp(Ht[1,1])-1)
covPrecio[2,2] <- pt[2]^2*exp(Ht[2,2])*(exp(Ht[2,2])-1)
covPrecio[3,3] <- pt[3]^2*exp(Ht[3,3])*(exp(Ht[3,3])-1)
covPrecio[1,2] <- pt[1]*pt[2]*exp((Ht[1,1]+Ht[2,2])*.5)*(exp(Ht[1,2])-1)
covPrecio[1,3] <- pt[1]*pt[3]*exp((Ht[1,1]+Ht[3,3])*.5)*(exp(Ht[1,3])-1)
covPrecio[2,3] <- pt[2]*pt[3]*exp((Ht[2,2]+Ht[3,3])*.5)*(exp(Ht[2,3])-1)
covPrecio[3,2] <- covPrecio[2,3]
covPrecio[3,1]<- covPrecio[1,3]
covPrecio[2,1] <- covPrecio[1,2]


rownames(covPrecio) <- c("OMA","UGPA","DIS")
colnames(covPrecio) <- c("OMA","UGPA","DIS")
kable(covPrecio,digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Pronósticos step-by-step al 31/01/2020")

```

Ahora continuamos con los dinamicos

```{r}

####### Dinámicos ###########
n <- nrow(rOMA["2020-01"])
rOMA.model7.out <- ugarchfit(spec = rOMA.model7.espec, data=rOMA["/2020-01-31"], out.sample = n )
rOMA.model7.forecast <- ugarchforecast(rOMA.model7.out, n.ahead=n)
rOMA.model7.forecast.sigma <- sigma(rOMA.model7.forecast)
vecdynOMA1 <- rOMA.model7.forecast.sigma
sigPut1OMA <- mean(rOMA.model7.forecast.sigma)

rUGPA.model7.out <- ugarchfit(spec = rUGPA.model7.espec, data=rUGPA["/2020-01-31"], out.sample = n )
rUGPA.model7.forecast <- ugarchforecast(rUGPA.model7.out, n.ahead=n)
rUGPA.model7.forecast.sigma <- sigma(rUGPA.model7.forecast)
vecdynUGPA1 <- rUGPA.model7.forecast.sigma
sigPut1UGPA <- mean(rUGPA.model7.forecast.sigma)

rDIS.model7.out <- ugarchfit(spec = rDIS.model7.espec, data=rDIS["/2020-01-31"], out.sample = n )
rDIS.model7.forecast <- ugarchforecast(rDIS.model7.out, n.ahead=n)
rDIS.model7.forecast.sigma <- sigma(rDIS.model7.forecast)
vecdynDIS1 <- rDIS.model7.forecast.sigma
sigPut1DIS <- mean(rDIS.model7.forecast.sigma)



sigmaOMAt <- rOMA.model7.forecast.sigma[n]
sigmaUGPAt <- rUGPA.model7.forecast.sigma[n]
sigmaDISt  <- rDIS.model7.forecast.sigma[n]

Dt <- diag(x=as.numeric(c(sigmaOMAt,sigmaUGPAt,sigmaDISt)))
Ht <- Dt%*%C%*%Dt
covRendDyn1 <- Ht
pOMAt <- as.numeric(dataxts[taux+1,1])*exp(sum(rOMA.model7.forecast.sigma)*.5)
pUPGAt <- as.numeric(dataxts[taux+1,2])*exp(sum(rUGPA.model7.forecast.sigma)*.5)
pDISt <- as.numeric(dataxts[taux+1,3])*exp(sum(rDIS.model7.forecast.sigma)*.5)
pt <- c(pOMAt,pUPGAt,pDISt)


covPrecio <- matrix(0,3,3)
covPrecio[1,1] <- pt[1]^2*exp(Ht[1,1])*(exp(Ht[1,1])-1)
covPrecio[2,2] <- pt[2]^2*exp(Ht[2,2])*(exp(Ht[2,2])-1)
covPrecio[3,3] <- pt[3]^2*exp(Ht[3,3])*(exp(Ht[3,3])-1)
covPrecio[1,2] <- pt[1]*pt[2]*exp((Ht[1,1]+Ht[2,2])*.5)*(exp(Ht[1,2])-1)
covPrecio[1,3] <- pt[1]*pt[3]*exp((Ht[1,1]+Ht[3,3])*.5)*(exp(Ht[1,3])-1)
covPrecio[2,3] <- pt[2]*pt[3]*exp((Ht[2,2]+Ht[3,3])*.5)*(exp(Ht[2,3])-1)
covPrecio[3,2] <- covPrecio[2,3]
covPrecio[3,1]<- covPrecio[1,3]
covPrecio[2,1] <- covPrecio[1,2]



rownames(covPrecio) <- c("OMA","UGPA","DIS")
colnames(covPrecio) <- c("OMA","UGPA","DIS")
kable(covPrecio,digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Pronósticos dinámicos al 31/01/2020")




```



## Matriz de covarianza de precios al 28/02/2020

Ahora queremos repetir el procedimiento para los pronósticos dinámicos y para los pronósticos step-by-step de los precios de cada activo hasta el 28 de febrero de 2020. Empezamos con los step-by-step.

```{r}

######### Step by Step .###########
n <- nrow(rOMA["2020-01/2020-02"])
rOMA.model7.out <- ugarchfit(spec = rOMA.model7.espec, data=rOMA["/2020-02-28"], out.sample = n )
rOMA.model7.forecast <- ugarchforecast(rOMA.model7.out, n.ahead=1,n.roll=n-1)
rOMA.model7.forecast.sigma <- sigma(rOMA.model7.forecast)
sigPut2OMA <- mean(rOMA.model7.forecast.sigma)
vecssOMA2 <- rOMA.model7.forecast.sigma

rUGPA.model7.out <- ugarchfit(spec = rUGPA.model7.espec, data=rUGPA["/2020-02-28"], out.sample = n )
rUGPA.model7.forecast <- ugarchforecast(rUGPA.model7.out, n.ahead=1,n.roll=n-1)
rUGPA.model7.forecast.sigma <- sigma(rUGPA.model7.forecast)
sigPut2UGPA <- mean(rUGPA.model7.forecast.sigma)
vecssUGPA2 <- rUGPA.model7.forecast.sigma

rDIS.model7.out <- ugarchfit(spec = rDIS.model7.espec, data=rDIS["/2020-02-28"], out.sample = n )
rDIS.model7.forecast <- ugarchforecast(rDIS.model7.out, n.ahead=1,n.roll=n-1)
rDIS.model7.forecast.sigma <- sigma(rDIS.model7.forecast)
sigPut2DIS <- mean(rDIS.model7.forecast.sigma)
vecssDIS2 <- rDIS.model7.forecast.sigma


# preciosOMAss2 <- as.numeric(dataxts["2019-12-30/2020-02-27",1])*exp(rOMA.model7.forecast.sigma*.5)
# preciosUGPAss2 <- as.numeric(dataxts["2019-12-30/2020-02-27",2])*exp(rUGPA.model7.forecast.sigma*.5)
# preciosDISss2 <- as.numeric(dataxts["2019-12-30/2020-02-27",3])*exp(rDIS.model7.forecast.sigma*.5)



sigmaOMAt <- rOMA.model7.forecast.sigma[n]
sigmaUGPAt <- rUGPA.model7.forecast.sigma[n]
sigmaDISt  <- rDIS.model7.forecast.sigma[n]

Dt <- diag(x=as.numeric(c(sigmaOMAt,sigmaUGPAt,sigmaDISt)))
Ht <- Dt%*%C%*%Dt
pOMAt <- dataxts[taux+n,1]
pUPGAt <- dataxts[taux+n,2]
pDISt <- dataxts[taux+n,3]
pt <- c(pOMAt,pUPGAt,pDISt)


covPrecio <- matrix(0,3,3)
covPrecio[1,1] <- pt[1]^2*exp(Ht[1,1])*(exp(Ht[1,1])-1)
covPrecio[2,2] <- pt[2]^2*exp(Ht[2,2])*(exp(Ht[2,2])-1)
covPrecio[3,3] <- pt[3]^2*exp(Ht[3,3])*(exp(Ht[3,3])-1)
covPrecio[1,2] <- pt[1]*pt[2]*exp((Ht[1,1]+Ht[2,2])*.5)*(exp(Ht[1,2])-1)
covPrecio[1,3] <- pt[1]*pt[3]*exp((Ht[1,1]+Ht[3,3])*.5)*(exp(Ht[1,3])-1)
covPrecio[2,3] <- pt[2]*pt[3]*exp((Ht[2,2]+Ht[3,3])*.5)*(exp(Ht[2,3])-1)
covPrecio[3,2] <- covPrecio[2,3]
covPrecio[3,1]<- covPrecio[1,3]
covPrecio[2,1] <- covPrecio[1,2]

rownames(covPrecio) <- c("OMA","UGPA","DIS")
colnames(covPrecio) <- c("OMA","UGPA","DIS")
kable(covPrecio,digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Pronósticos step-by-step al 28/02/2020")


```

Este brinco en la volatilidad se debe a que justo al final del febrero se presentan los primeros casos de volatilidad por el COVID, lo que hace que la serie brinque de forma inesperada.

Continuamos con los dinámicos

```{r}

####### Dinámicos ###########
n <- nrow(rOMA["2020-01/2020-02"])
rOMA.model7.out <- ugarchfit(spec = rOMA.model7.espec, data=rOMA["/2020-02-28"], out.sample = n )
rOMA.model7.forecast <- ugarchforecast(rOMA.model7.out, n.ahead=n)
rOMA.model7.forecast.sigma <- sigma(rOMA.model7.forecast)
vecdynOMA2 <- rOMA.model7.forecast.sigma

rUGPA.model7.out <- ugarchfit(spec = rUGPA.model7.espec, data=rUGPA["/2020-02-28"], out.sample = n )
rUGPA.model7.forecast <- ugarchforecast(rUGPA.model7.out, n.ahead=n)
rUGPA.model7.forecast.sigma <- sigma(rUGPA.model7.forecast)
vecdynUGPA2 <- rUGPA.model7.forecast.sigma

rDIS.model7.out <- ugarchfit(spec = rDIS.model7.espec, data=rDIS["/2020-02-28"], out.sample = n )
rDIS.model7.forecast <- ugarchforecast(rDIS.model7.out, n.ahead=n)
rDIS.model7.forecast.sigma <- sigma(rDIS.model7.forecast)
vecdynDIS2 <- rDIS.model7.forecast.sigma

sigmaOMAt <- rOMA.model7.forecast.sigma[n]
sigmaUGPAt <- rUGPA.model7.forecast.sigma[n]
sigmaDISt  <- rDIS.model7.forecast.sigma[n]

Dt <- diag(x=as.numeric(c(sigmaOMAt,sigmaUGPAt,sigmaDISt)))
Ht <- Dt%*%C%*%Dt
pOMAt <- as.numeric(dataxts[taux+1,1])*exp(sum(rOMA.model7.forecast.sigma)*.5)
pUPGAt <- as.numeric(dataxts[taux+1,2])*exp(sum(rUGPA.model7.forecast.sigma)*.5)
pDISt <- as.numeric(dataxts[taux+1,3])*exp(sum(rDIS.model7.forecast.sigma)*.5)
pt <- c(pOMAt,pUPGAt,pDISt)



covPrecio <- matrix(0,3,3)
covPrecio[1,1] <- pt[1]^2*exp(Ht[1,1])*(exp(Ht[1,1])-1)
covPrecio[2,2] <- pt[2]^2*exp(Ht[2,2])*(exp(Ht[2,2])-1)
covPrecio[3,3] <- pt[3]^2*exp(Ht[3,3])*(exp(Ht[3,3])-1)
covPrecio[1,2] <- pt[1]*pt[2]*exp((Ht[1,1]+Ht[2,2])*.5)*(exp(Ht[1,2])-1)
covPrecio[1,3] <- pt[1]*pt[3]*exp((Ht[1,1]+Ht[3,3])*.5)*(exp(Ht[1,3])-1)
covPrecio[2,3] <- pt[2]*pt[3]*exp((Ht[2,2]+Ht[3,3])*.5)*(exp(Ht[2,3])-1)
covPrecio[3,2] <- covPrecio[2,3]
covPrecio[3,1]<- covPrecio[1,3]
covPrecio[2,1] <- covPrecio[1,2]

rownames(covPrecio) <- c("OMA","UGPA","DIS")
colnames(covPrecio) <- c("OMA","UGPA","DIS")
kable(covPrecio,digits=5)%>%
  kable_styling(position = "center")%>%
  footnote(general = "Pronósticos dinámicos al 28/02/2020")
```

# OPCIONES PUT

## Opción con vencimiento al 31/01/2020

Queremos calcular los precios de un put con vencimiento al 31/01/2020, utilizando la varianza promedio de los pronósticos dinámicos, realizados anteriormente.

```{r}
BlackScholes <- function(S, K, r, T, sig, type,d){
  
  if(type==1){
  d1 <- (log(S/K) + (r -d + sig^2/2)*T) / (sig*sqrt(T))
  d2 <- d1 - sig*sqrt(T)
  
  value <- S*exp(-d*T)*pnorm(d1) - K*exp(-r*T)*pnorm(d2)
  }
  
  if(type==2){
  d1 <- (log(S/K) + (r -d + sig^2/2)*T) / (sig*sqrt(T))
  d2 <- d1 - sig*sqrt(T)
  
   value <-  (K*exp(-r*T)*pnorm(-d2) - S*exp(-d*T)*pnorm(-d1))
  }
  
  if(type!=1  && type!=2){
    value="ERROR EN TIPO"
  }
  return(value)
}

```

Primero calculamos los valores. Usaremos días de trading como valor del año. Por lo tanto el vencimiento $T=\frac{n}{252}$ donde $n$ es el número de días al vencimiento. Adicionalmente, la desviación estandár se cálcula como el promedio de las varianzas usadas en el step-by-step y se anualiza tal que $\sigma_Y = \sigma_D \sqrt{252}$ donde $\sigma_D$ es el promedio calculado.

```{r}
sOMA <- dataxts[taux+1,1]
KOMA <- dataxts[taux+1,1]
r <- 0.03
tOMA <- length(rOMA["2020-01"])/252
sigOMA <- sigPut1OMA*sqrt(252)
d <- 0

sUGPA <- dataxts[taux+1,2]
KUGPA <- dataxts[taux+1,2]
r <- 0.03
tUGPA <- length(rUGPA["2020-01"])/252
sigUGPA <- sigPut1UGPA*sqrt(252)
d <- 0

sDIS <- dataxts[taux+1,3]
KDIS <- dataxts[taux+1,3]
r <- 0.03
tDIS <- length(rDIS["2020-01"])/252
sigDIS <- sigPut1DIS*sqrt(252)
d <- 0

OMA <- as.numeric(cbind(sOMA,KOMA,r,tOMA,sigOMA,d))
UGPA <- as.numeric(cbind(sUGPA,KUGPA,r,tUGPA,sigUGPA,d))
DIS <-  as.numeric(cbind(sDIS,KDIS,r,tDIS,sigDIS,d))
dataPut1 <- rbind(OMA,UGPA,DIS)
colnames(dataPut1) <- c("Current Price",
                     "Strike Price",
                     "r interest rate",
                     "T time to maturity",
                     "Annualized sigma",
                     "d dividend rate")
rownames(dataPut1) <- c("OMA","UGPA","DIS")

kable(t(dataPut1),digits=2)%>%
  kable_styling(position = "center")
```

El precio de cada put se muestra en la siguiente tabla.

```{r}
# (S, K, r, T, sig, type,d)


tablePut1 <- cbind(
  BlackScholes(dataPut1[1,1],dataPut1[1,2],dataPut1[1,3],dataPut1[1,4],dataPut1[1,5],2,dataPut1[1,6]),
  BlackScholes(dataPut1[2,1],dataPut1[2,2],dataPut1[2,3],dataPut1[2,4],dataPut1[1,5],2,dataPut1[2,6]),
  BlackScholes(dataPut1[3,1],dataPut1[3,2],dataPut1[3,3],dataPut1[3,4],dataPut1[1,5],2,dataPut1[3,6]))

rownames(tablePut1) <- "Precio del Put"
colnames(tablePut1) <- c("OMA","UGPA","DIS")
kable(tablePut1,digits=2)%>%
  kable_styling(position = "center")

```

La ganancia de cada opción considerando el costo de pagar el put lo podemos ver en la siguiente tabla.

```{r}
taux2 <- which(index(rOMA)=="2020-01-31")

payoffOMA <- as.numeric(KOMA)-as.numeric(dataxts[taux2+1,1])-tablePut1[1]
payoffUGPA <- as.numeric(KUGPA)-as.numeric(dataxts[taux2+1,2])-tablePut1[2]
payoffDIS <- as.numeric(KDIS)-as.numeric(dataxts[taux2+1,3])-tablePut1[3]

ptaux2 <- c(as.numeric(dataxts[taux2+1,1]),as.numeric(dataxts[taux2+1,2]),as.numeric(dataxts[taux2+1,3]))

tablePayoff1 <- cbind(payoffOMA,payoffUGPA,payoffDIS)
tablePayoff1 <- rbind(ptaux2,tablePayoff1)
colnames(tablePayoff1) <- c("OMA","UGPA","DIS")
rownames(tablePayoff1) <- c("Precio al vencimiento","Payoff al vencimiento")


kable(tablePayoff1,digits=2)%>%
  kable_styling(position = "center")
```



## Opción con vencimiento al 28/02/2020

Queremos calcular los precios de un put con vencimiento al 28/02/2020, utilizando la varianza promedio de los pronósticos step-by-step, realizados anteriormente.

Primero calculamos los valores. Usaremos días de trading como valor del año. Por lo tanto el vencimiento $T=\frac{n}{252}$ donde $n$ es el número de días al vencimiento. Adicionalmente, la desviación estandár se cálcula como el promedio de las varianzas usadas en el step-by-step y se anualiza tal que $\sigma_Y = \sigma_D \sqrt{252}$ donde $\sigma_D$ es el promedio calculado.
```{r}
sOMA <- dataxts[taux+1,1]
KOMA <- dataxts[taux+1,1]
r <- 0.03
tOMA <- length(rOMA["2020-01/2020-02"])/252
sigOMA <- sigPut2OMA*sqrt(252)
d <- 0

sUGPA <- dataxts[taux+1,2]
KUGPA <- dataxts[taux+1,2]
r <- 0.03
tUGPA <- length(rUGPA["2020-01/2020-02"])/252
sigUGPA <- sigPut2UGPA*sqrt(252)
d <- 0

sDIS <- dataxts[taux+1,3]
KDIS <- dataxts[taux+1,3]
r <- 0.03
tDIS <- length(rDIS["2020-01/2020-02"])/252
sigDIS <- sigPut2DIS*sqrt(252)
d <- 0

OMA <- as.numeric(cbind(sOMA,KOMA,r,tOMA,sigOMA,d))
UGPA <- as.numeric(cbind(sUGPA,KUGPA,r,tUGPA,sigUGPA,d))
DIS <-  as.numeric(cbind(sDIS,KDIS,r,tDIS,sigDIS,d))
dataPut2 <- rbind(OMA,UGPA,DIS)
colnames(dataPut2) <- c("Current Price",
                     "Strike Price",
                     "r interest rate",
                     "T time to maturity",
                     "Annualized sigma",
                     "d dividend rate")
rownames(dataPut2) <- c("OMA","UGPA","DIS")

kable(t(dataPut2),digits=2)%>%
  kable_styling(position = "center")
```

El precio de cada put se muestra en la siguiente tabla

```{r}
# (S, K, r, T, sig, type,d)


tablePut2 <- cbind(
  BlackScholes(dataPut2[1,1],dataPut2[1,2],dataPut2[1,3],dataPut2[1,4],dataPut2[1,5],2,dataPut2[1,6]),
  BlackScholes(dataPut2[2,1],dataPut2[2,2],dataPut2[2,3],dataPut2[2,4],dataPut2[1,5],2,dataPut2[2,6]),
  BlackScholes(dataPut2[3,1],dataPut2[3,2],dataPut2[3,3],dataPut2[3,4],dataPut2[1,5],2,dataPut2[3,6]))


rownames(tablePut2) <- "Precio del Put"
colnames(tablePut2) <- c("OMA","UGPA","DIS")
kable(tablePut2,digits=2)%>%
  kable_styling(position = "center")


```

La ganancia de cada opción considerando el costo de pagar el put lo podemos ver en la siguiente tabla.

```{r}
taux3 <- which(index(rOMA)=="2020-02-28")

payoffOMA <- as.numeric(KOMA)-as.numeric(dataxts[taux3+1,1])-tablePut2[1]
payoffUGPA <- as.numeric(KUGPA)-as.numeric(dataxts[taux3+1,2])-tablePut2[2]
payoffDIS <- as.numeric(KDIS)-as.numeric(dataxts[taux3+1,3])-tablePut2[3]

ptaux3 <- c(as.numeric(dataxts[taux3+1,1]),as.numeric(dataxts[taux3+1,2]),as.numeric(dataxts[taux3+1,3]))

tablePayoff2 <- cbind(payoffOMA,payoffUGPA,payoffDIS)
tablePayoff2 <- rbind(ptaux3,tablePayoff2)
colnames(tablePayoff2) <- c("OMA","UGPA","DIS")
rownames(tablePayoff2) <- c("Precio al vencimiento","Payoff al vencimiento")

kable(tablePayoff2,digits=2)%>%
  kable_styling(position = "center")
```

## Opción con vencimiento al 31/01/2020 y Varianza de GARCH CCC.

Usaremos el promedio de la desviación estándar de los pronósticos dinámicos GARCH CCC, como la desviación estándar para el cálculo del Put con la fórmula de Black-Scholes-Merton.
```{r}
numEl <- length(vecdynOMA1)
sumSigmaDyn1 <- 0

for (i in 1:numEl){
  Dtdyn1 <- diag( as.numeric( c( vecdynOMA1[i] , vecdynUGPA1[i] , vecdynDIS1[i] ) ) )
  Htdyn1 <- Dtdyn1 %*% C %*% Dtdyn1
  sumSigmaDyn1 <- sumSigmaDyn1+ sqrt(sum(Htdyn1))
}
sigDyn1 <- 1/3*sumSigmaDyn1 / numEl


##### Presentación de datos ###########
sProm <- 1/3*(dataxts[taux+1,1]+ dataxts[taux+1,2]+dataxts[taux+1,3])
KProm <- sProm
r <- 0.03
tProm <- length(rOMA["2020-01"])/252
sigProm <- sigDyn1*sqrt(252)
d <- 0


prom <- as.numeric(cbind(sProm,KProm,r,tProm,sigProm,d))

dataPut3 <- rbind(prom)
colnames(dataPut3) <- c("Current Price",
                     "Strike Price",
                     "r interest rate",
                     "T time to maturity",
                     "Annualized sigma",
                     "d dividend rate")
rownames(dataPut3) <- c("Promedio")

kable(t(dataPut3),digits=2)%>%
  kable_styling(position = "center")
```

```{r}
# (S, K, r, T, sig, type,d)

tablePut3 <- cbind(
  BlackScholes(dataPut3[1,1],dataPut3[1,2],dataPut3[1,3],dataPut3[1,4],dataPut3[1,5],2,dataPut3[1,6]))


rownames(tablePut3) <- "Precio del Put"
colnames(tablePut3) <- c("Promedio")
kable(tablePut3,digits=2)%>%
  kable_styling(position = "center")

```

```{r}

promfinal <- mean(dataxts[taux2+1])
payoffProm <- as.numeric(KProm)-as.numeric(promfinal)-tablePut3[1]


ptaux2 <- c(promfinal)

tablePayoff3 <- cbind(payoffProm)
tablePayoff3 <- rbind(ptaux2,tablePayoff3)
colnames(tablePayoff3) <- c("Promedio")
rownames(tablePayoff3) <- c("Precio al vencimiento","Payoff al vencimiento")

kable(tablePayoff3,digits=2)%>%
  kable_styling(position = "center")
```

## Opción con vencimiento al 28/02/2020 y Varianza de GARCH CCC.

Usaremos el promedio de la desviación estándar de los pronósticos step-by-step GARCH CCC, como la desviación estándar para el cálculo del Put con la fórmula de Black-Scholes-Merton.
```{r}
numEl2 <- length(vecssOMA2)
sumss2 <- 0
for (i in 1:numEl2){
  Dtss2 <- diag( as.numeric( c( vecssOMA2[i] , vecssUGPA2[i] , vecssDIS2[i] ) ) )
  Htss2 <- Dtss2 %*% C %*% Dtss2
  sumss2 <- sumss2 +sqrt(1/9*sum(Htss2))
  }
sigss2 <- sumss2 / numEl2


##### Presentación de datos ###########
sProm <- 1/3*(dataxts[taux+1,1]+ dataxts[taux+1,2]+dataxts[taux+1,3])
KProm <- sProm
r <- 0.03
tProm <- length(rOMA["2020-01/2020-02"])/252
sigProm <- sigss2*sqrt(252)
d <- 0

prom <- as.numeric(cbind(sProm,KProm,r,tProm,sigProm,d))

dataPut4 <- rbind(prom)
colnames(dataPut4) <- c("Current Price",
                     "Strike Price",
                     "r interest rate",
                     "T time to maturity",
                     "Annualized sigma",
                     "d dividend rate")
rownames(dataPut4) <- c("Promedio")

kable(t(dataPut4),digits=2)%>%
  kable_styling(position = "center")
```

```{r}
# (S, K, r, T, sig, type,d)

tablePut4 <- cbind(
  BlackScholes(dataPut4[1,1],dataPut4[1,2],dataPut4[1,3],dataPut4[1,4],dataPut4[1,5],2,dataPut4[1,6]))


rownames(tablePut4) <- "Precio del Put"
colnames(tablePut4) <- c("Promedio")
kable(tablePut4,digits=2)%>%
  kable_styling(position = "center")

```

```{r}

promfinal <- mean(dataxts[taux3+1])
payoffProm <- as.numeric(KProm)-as.numeric(promfinal)-tablePut4[1]


ptaux3 <- c(promfinal)

tablePayoff4 <- cbind(payoffProm)
tablePayoff4 <- rbind(ptaux3,tablePayoff4)
colnames(tablePayoff4) <- c("Promedio")
rownames(tablePayoff4) <- c("Precio al vencimiento","Payoff al vencimiento")

kable(tablePayoff4,digits=2)%>%
  kable_styling(position = "center")

```
Notamos una ganancia mayor a comparación del put anterior, esto se debe principalmente a la disminución en los precios de las tres acciones por la crisis del COVID, resultando en un precio promedio mucho menor al strike lo cuál impulsa el valor intrínseco del put.

# PORTAFOLIO DE MÍNIMA VARIANZA

Ahora queremos construir el portafolio de mínima varianza para los tres activos en cuestión. Para realizarlo tenemos que conocer la matriz de varianzas y covarianzas de los rendimientos de los tres activos. Para cumplir con este objetivo usaremos matriz de varianzas y covarianzas en rendimientos pronósticados dinámicamente al 31/01/2020 del GARCH CCC. En la siguiente tabla podemos ver los resultados en valor porcentual.

```{r}

rownames(covRendDyn1) <- c("OMA","UGPA","DIS" )
colnames(covRendDyn1) <- c("OMA","UGPA","DIS" )
kable(covRendDyn1*100,digits=5,)%>%
  kable_styling(position = "center") %>%
  footnote(general = "Todos los valores son porcentuales (%)")
```
Ahora buscamos los pesos $\gamma$ tales que minimizen la función de desviación estándar. Definimos $\Sigma$ como la matriz de varianzas y covarianzas. De esta forma, la desviación estándar del portafolio está dada por. $$ \sigma_P = \sqrt{\gamma^{T}\Sigma\gamma}$$ 

```{r}
desvEstanPort <- function(pesos){
  ## consideramos que el vector de pesos es columna.
  pesos2 <- matrix(0,3,1)
  pesos2[1:2] <- pesos
  pesos2[3] <- 1-sum(pesos)
  pesos2 <- as.matrix(pesos2)
  sigma <- as.matrix(covRendDyn1)
  value = sqrt(t(pesos2) %*% sigma %*% pesos2)
  return (value)
}

minVarOptim <- optim(par=c(.5,.2),fn=desvEstanPort, method = "L-BFGS-B", lower=c(0,0), upper = c(1,1))


minVarW <- matrix(0,3,1)
minVarW[1:2] <- minVarOptim$par[1:2]
minVarW[3] <- 1-sum(minVarW)

minSigma <- desvEstanPort(minVarOptim$par)
minSigmaAnual <- minSigma*sqrt(252)
```

Obtenemos los pesos que minimizan la varianza, que se muestran en la siguiente tabla, hay que considerar que se considero la restricción de no tener ventas en corto, por lo tanto, todos los pesos son positivos.
```{r}
rownames(minVarW) <- c("OMA","UGPA","DIS")
colnames(minVarW) <- "Pesos (%)"
kable(minVarW*100,digits=2)%>%
  kable_styling(position = "center")%>%
  footnote(general="Valores minimizados con Limited Memory BFGS en R")


```
Adicionalmente el valor de varianza mínima es `r round(minSigma*100,4)`%. Dando un valor anualizado de `r round(minSigmaAnual*100,4)`%.

Ahora queremos ver el comportamiento del portafolio desde el 2 de enero hasta el 28 de Abril del 2020.
```{r}
inicial <- 100
numElemPort <- length(rOMA["2020"])
valorPort <- matrix(0,numElemPort+1,1)
valorPort[1] <- inicial
for (i in 1:numElemPort){
  rendActivos <- as.matrix(c(rOMA["2020"][i],rUGPA["2020"][i],rDIS["2020"][i]))
  rendPort <- t(as.matrix(minVarW)) %*% rendActivos
  valorPort[i+1] <- valorPort[i]*exp(rendPort)
}
valorPortxts <- xts(valorPort,order.by = index(rOMA["2019-12-30/2020-"]) )
plot(valorPortxts)
rendTotal <- -as.numeric(100-valorPortxts[numElemPort+1])

```

Vemos que tener posiciones largas en las acciones ha sido poco beneficioso. Si consideramos una inversión de 100 USD en el portafolio entonces el rendimiento es de `r round(rendTotal,2)` USD, o equivalentemente `r round(rendTotal,2)`%. Esto se debe principalmente a las caídas de los precios de todas las acciones consideradas en el portafolio dado el COVID-19.

# COMPARACIÓN DE MATRICES DE CORRELACCIÓN CCC

Ahora ajustamos los modelos seleccionados hasta el 28 de Abril del 2020.

```{r}

####### Reajustando OMA ##############
ind1OMAVec2 <- matrix(0,length(rOMA),1)
ind1OMAVec2[which(index(rOMA)==ind1OMA)] <- 1
ind2OMAVec2 <- matrix(0,length(rOMA),1)
ind2OMAVec2[which(index(rOMA)==ind2OMA)] <- 1
ind5OMAVec2 <- matrix(0,length(rOMA),1)
ind5OMAVec2[which(index(rOMA)==ind5OMA)] <- 1
indicators2 <- as.matrix(cbind(ind1OMAVec2,ind2OMAVec2,ind5OMAVec2))


rOMA.model7.espec2 <- ugarchspec(
  variance.model=list(model="eGARCH",garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F,external.regressors = indicators2),
  distribution.model = "ged")
rOMA.model7.fit2 <- ugarchfit(rOMA.model7.espec2, data=rOMA)
rOMA.model7.fit2.res <- residuals(rOMA.model7.fit2)/sigma(rOMA.model7.fit2)

```

```{r}
####### Reajustando UGPA ##############
ind1UGPAVec2 <- matrix(0,length(rUGPA),1)
ind1UGPAVec2[which(index(rUGPA)==ind1UGPA)] <- 1
ind2UGPAVec2 <- matrix(0,length(rUGPA),1)
ind2UGPAVec2[which(index(rUGPA)==ind2UGPA)] <- 1
indicators2 <- as.matrix(cbind(ind1UGPAVec2,ind2UGPAVec2))


rUGPA.model7.espec2 <- ugarchspec(
  variance.model=list(model="eGARCH",garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F,external.regressors = indicators2),
  distribution.model = "ged")
rUGPA.model7.fit2 <- ugarchfit(rUGPA.model7.espec2, data=rUGPA)
rUGPA.model7.fit2.res <- residuals(rUGPA.model7.fit2)/sigma(rUGPA.model7.fit2)

```

```{r}
####### Reajustando DIS ##############
ind1DISVec2 <- matrix(0,length(rDIS),1)
ind1DISVec2[which(index(rDIS)==ind1DIS)] <- 1
ind2DISVec2 <- matrix(0,length(rDIS),1)
ind2DISVec2[which(index(rDIS)==ind2DIS)] <- 1
indicators2 <- as.matrix(cbind(ind1DISVec2,ind2DISVec2))


rDIS.model7.espec2 <- ugarchspec(
  variance.model=list(model="eGARCH",garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(0,0), include.mean=F,external.regressors = indicators2),
  distribution.model = "ged")
rDIS.model7.fit2 <- ugarchfit(rDIS.model7.espec2, data=rDIS)
rDIS.model7.fit2.res <- residuals(rDIS.model7.fit2)/sigma(rDIS.model7.fit2)

```

La matriz de correlación que tenemos ahora es:
```{r}
C2 <- cor(x=cbind(rOMA.model7.fit2.res,rUGPA.model7.fit2.res,rDIS.model7.fit2.res),
          y=cbind(rOMA.model7.fit2.res,rUGPA.model7.fit2.res,rDIS.model7.fit2.res))
rownames(C2) <- c("OMA Res Est","UGPA Res Est","DIS Res Est")
colnames(C2) <- c("OMA Res Est","UGPA Res Est","DIS Res Est")
kable(C2,digits=4, caption = "Matriz de correlaciones ajuste hasta 28/04/2020")%>%
  kable_styling(position = "center")

```

Recordamos que la matrix de correlaciones anterior, ajustada solamente hasta el 31 de diciembre de 2019.
```{r}
kable(C,digits=4,caption = "Matriz de correlaciones ajuste hasta 31/12/2019")%>%
  kable_styling(position = "center")
```
Notamos que hay un incremento significativo en las correlaciones entre los tres activos. La correlación de OMA y Ultrapar aumenta de `r round(C[1,2],4)` a `r round(C2[1,2],4)`, la de OMA y Disney pasa de `r round(C[1,3],4)` a `r round(C2[1,2],4)` y finalmente la de Ultrapar y Disney aumenta de `r round(C[2,3],4)` `r round(C[2,3],4)`. Esto efecto en el aumento de las correlaciones se puede deber a que las tres compañias han sido afectadas de manera similar por la crisis del COVID, todas han tenido una pérdida fuerte. Al tener movimientos similares en sus precios y rendimientos, la correlación de los errores aumenta. Adicionalmente, es importante ver que la correlación entre dos de los tres activos mantiene el signo positivo, cosa que esperabamos ya que durante 2020 se han movido en el mismo sentido, teniendo rendimientos negativos grandes, aunado al hecho de que ya eran positivas desde antes de la crisis del COVID. 

# CONCLUSIONES

En este proyecto realizamos un análisis de series de tiempo sobre las acciones de Grupo Aeroportuario del Centro Norte, Ultrapar Participaceos SA y Walt Disney Company. Donde ajustamos diferentes modelos GARCH para cada una, resultado en 3 modelos diferentes para cada acción. Para OMA obtuvimos  EGARCH (1,1) NC GED con Indicadoras, de esta forma ajustamos por la asimetría en sus resultados y para las colas pesadas. Adiconalmente, las indicadoras nos ayudan a ajustar para los rendimientos atípicos de la serie. Para Ultrapar llegamos al modelo GARCH (1,1) NC GED con indicadores, que solamente ajusta para las colas pesadas y los casos atípicos. Finalmente, para Disney ajustamos un modelo GARCH (1,1) NC t-Student con Indicadoras, para ajustar las colas pesadas y los casos atípicos. Por lo tanto, vemos que los tres modelos presentan colas más pesadas que una distribución normal y que particularmente Disney es la única con distribución t-Student mientras que las otras dos tienen distribución GED.

Más a fondo, ajustamos un modelo MULTIGARCH CCC donde cabe recalcar que las correlaciones entre activos es positiva. Una vez que ajustamos estos modelos pudimos determinar la relación con precios y varias opciones put. En las opciones put, cabe recalcar que para un activo solamente y con fecha de vencimiento al 31 de enero del 2020 para algunos activos se hubiera perdido y para otros se hubiera ganado. Mientras que para un vencimiento del 28 de Febero del 2020 todos los puts tienen payoff neto positivo, esto se debe principalmente a que los precios caen por la presencia de la crisis del COVID, donde las tres acciones presentaron caídas fuertes y el pago del put aumenta significativamente.

Por otro lado, realizamos un portafolio cuyos pesos fueron seleccionados minimizando la varianza, usando como matriz de covarianzas la es de los pronósticos dinámicos al 31 de enero del 2020. Al ver la evolución del portafolio notamos que pierde significativamente su valor una vez que entra la presencia de la crisis del COVID. Esta pérdida significativa en su valor se debe a que todas las acciones presentan caídas por el COVID y el vector de pesos tiene la restricción de ser estrictamente positivo.

El último análisis realizado muestra las diferencias en las correlaciones para diferentes tiempos, donde notamos que las correlaciones entre activos aumenta con la presencia del COVID, esto se puede deber a que todas las acciones caen fuertemente durante este periodo, por lo tanto, los movimientos en el mismo sentido pudieron haber aumentado las correlaciones. 

\newpage 

# ANEXOS

Incluimos otros modelos relevantes para cada acción pero no ponemos la salida de todos por espacio. 

## Anexos Grupo Aeroportuario del Centro Norte

### 5. GJR-GARCH (1,1) NC t-Student

```{r}
rOMA.model5.fit
#### Model 5 #####
rOMA.model5.fit.res <- residuals(rOMA.model5.fit)/sigma(rOMA.model5.fit)
plot(rOMA.model5.fit.res)

plot(rOMA.model5.fit, which = "all")
Box.test(rOMA.model5.fit.res^2,lag=2,type="Ljung-Box")
```

\newpage
### 6. EGARCH (1,1) NC t-Student

```{r}
# #### Model 6 #####
rOMA.model6.fit
rOMA.model6.fit.res <- residuals(rOMA.model6.fit)/sigma(rOMA.model6.fit)
plot(rOMA.model6.fit.res)

plot(rOMA.model6.fit, which = "all")
Box.test(rOMA.model6.fit.res^2,lag=2,type="Ljung-Box")
rOMA.model6.fit
```

\newpage

## Anexos Ultrapar Participacoes SA

### 3. GARCH (1,1) NC t-Student

```{r}
#### Model 3 #####
rUGPA.model3.fit
rUGPA.model3.fit.res <- residuals(rUGPA.model3.fit)/sigma(rUGPA.model3.fit)
plot(rUGPA.model3.fit.res)

plot(rUGPA.model3.fit, which = "all")
Box.test(rUGPA.model3.fit.res^2,lag=2,type="Ljung-Box")
```

\newpage

### 5. GARCH (1,1) NC GED

```{r}
# #### Model 5 #####
rUGPA.model5.fit
rUGPA.model5.fit.res <- residuals(rUGPA.model5.fit)/sigma(rUGPA.model5.fit)
plot(rUGPA.model5.fit.res)

plot(rUGPA.model5.fit, which = "all")
Box.test(rUGPA.model5.fit.res^2,lag=2,type="Ljung-Box")

```


\newpage
## Anexos Walt Disney Co

### 3. GARCH (1,1) NC t-Student

```{r}
#### Model 3 #####
rDIS.model3.fit
rDIS.model3.fit.res <- residuals(rDIS.model3.fit)/sigma(rDIS.model3.fit)
plot(rDIS.model3.fit.res)

plot(rDIS.model3.fit, which = "all")
Box.test(rDIS.model3.fit.res^2,lag=2,type="Ljung-Box")
```

\newpage

### 4. GARCH (0,1) NC t-Student


```{r}
rDIS.model4.fit
rDIS.model4.fit.res <- residuals(rDIS.model4.fit)/sigma(rDIS.model4.fit)
plot(rDIS.model4.fit.res)

plot(rDIS.model4.fit, which = "all")
Box.test(rDIS.model4.fit.res^2,lag=2,type="Ljung-Box")

```

\newpage

### 5. GARCH (1,1) NC GED

```{r}
# #### Model 5 #####
rDIS.model5.fit
rDIS.model5.fit.res <- residuals(rDIS.model5.fit)/sigma(rDIS.model5.fit)
plot(rDIS.model5.fit.res)

plot(rDIS.model5.fit, which = "all")
Box.test(rDIS.model5.fit.res^2,lag=2,type="Ljung-Box")


```





